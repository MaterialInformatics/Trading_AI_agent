# Trading_AI_agent
The system generates synthetic data, trains a degradation model, optimizes battery charging/discharging decisions using reinforcement learning, and visualizes results.
The complete software system consists of four Python scripts designed to simulate, model, optimize, and visualize the operation of a battery energy storage system (BESS) in an electricity market. The system generates synthetic data, trains a degradation model, optimizes battery charging/discharging decisions using reinforcement learning, and visualizes results. The scripts are modular, interoperable, and tailored to work with the provided synthetic_data.csv format, which includes battery operational data, market prices, and degradation metrics. Below is a detailed description of the software, including the purpose, functionality, inputs, outputs, and interactions of each script.
# Overview
The software simulates a BESS operating in a market with Day-Ahead Market (DAM) and Real-Time Market (RTM) prices, aiming to maximize profit while minimizing battery degradation. It comprises four scripts:
generate_synthetic_data.py: Generates synthetic battery and market data.

train_degradation_model.py: Trains a RandomForestRegressor model to predict battery degradation.

train_ai_agent.py: Trains a Deep Q-Network (DQN) reinforcement learning agent to optimize battery operation and compares it against baseline strategies.

plot_results.py: Visualizes the synthetic data, model performance, and strategy comparison.

The system is designed to:
Mimic real-world BESS operation with realistic battery parameters and market dynamics.

Use machine learning (RandomForestRegressor) to model battery degradation.

Employ reinforcement learning (DQN) to optimize charging/discharging decisions.

Provide clear visualizations to analyze data and performance.

# Script Descriptions

## 1. generate_synthetic_data.py
Purpose: Generates synthetic minute-by-minute data for a BESS over 7 days, simulating battery operation and market prices, formatted to match the provided synthetic_data.csv.
Functionality:
Simulation Period: 7 days (2025-04-03 00:00:00 to 2025-04-09 23:59:00), producing 10,080 data points (7 × 24 × 60).

Battery Parameters:
Capacity: 360 Ah

Voltage: 1200 V (0% SOC) to 1400 V (100% SOC)

Nominal voltage: 1344 V

Max current: ±74.4 A

Cells in series: 414

Data Columns (matching synthetic_data.csv):
timestamp_utc: Timestamps (datetime)

seg_name, seg_id: Battery identifiers (static: "Battery_String_01_4B6BAT2", UUID)

Battery_Current: ±74.4 A (charge/discharge) or 0 A (idle)

Battery_Voltage: Linearly dependent on SOC

Cell_Voltage_Average, Max_1_Cell_Voltage_Value, Min_1_Cell_Voltage_Value: Derived from battery voltage

Cell_Temperature_Average, Cell_Temperature_1_Min, Cell_Temperature_1_Max: Sinusoidal with noise

SOC: State of Charge (0% to 100%)

Max_Cell_SOC, Min_Cell_SOC: SOC ± offset

Available_Charge_Capacity, Available_Discharge_Capacity: Based on SOC and capacity

__index_level_0__: Row index

DAM_price: Hourly prices, sinusoidal pattern

RTM_price: 5-minute prices, based on DAM with noise

degradation: Synthetic degradation based on SOC, delta_SOC, temperature, and current

Simulation Logic:
Random actions (charge, discharge, idle) drive battery state changes. Degradation is computed using a quadratic function of SOC deviation, delta_SOC, temperature deviation, and current.

Inputs: None (hard-coded parameters).
Outputs:
synthetic_data.csv: CSV file with 10,080 rows and 20 columns, containing all simulated data.

Dependencies: pandas, numpy

## 2. train_degradation_model.py
Purpose: Trains a RandomForestRegressor model to predict battery degradation based on operational features, enabling degradation-aware optimization.
Functionality:
Data Loading: Reads synthetic_data.csv.

Feature Engineering: Computes delta_SOC as the difference in consecutive SOC values, with the first value set to 0.

Features: SOC, delta_SOC, Cell_Temperature_Average, Battery_Current

Target: degradation

Model Training:
Uses RandomForestRegressor with 100 trees and a fixed random seed (42).

Splits data into 80% training and 20% testing.

Evaluation: Computes Mean Squared Error (MSE) on the test set.

Model Saving: Saves the trained model for use by other scripts.

Inputs:
synthetic_data.csv: Generated by generate_synthetic_data.py.

Outputs:
degradation_model.pkl: Serialized RandomForestRegressor model.

Console output: Test MSE and confirmation of model saving.

Dependencies: pandas, sklearn, joblib

## 3. train_ai_agent.py
Purpose: Trains a DQN reinforcement learning agent to optimize battery charging/discharging decisions, maximizing profit while minimizing degradation, and compares it against baseline strategies.
Functionality:
Data and Model Loading:
Reads synthetic_data.csv.

Loads degradation_model.pkl (RandomForestRegressor).

Computes delta_SOC for degradation predictions.

Environment (BatteryEnv):
State: [SOC, Battery_Current, Cell_Temperature_Average, RTM_price]

Actions: 0 (idle), 1 (charge), 2 (discharge)

Reward: Profit (revenue from discharging minus charging cost) minus degradation cost (degradation × 10,000)

Battery parameters match generate_synthetic_data.py (360 Ah, 1344 V, ±74.4 A).

DQN Agent:
Neural network with two hidden layers (128 units each, ReLU activation).

Trains over 10 episodes using epsilon-greedy exploration (epsilon decays from 1.0 to 0.01).

Updates target network every 100 steps.

Strategies Compared:
AI Agent: DQN-based optimization.

Always Charge: Charges at maximum current every step.

Always Discharge: Discharges at maximum current every step.

Simple RTM vs DAM: Charges if RTM < DAM, discharges if RTM > DAM, idles if equal.

Scenarios:
Low Price: RTM prices scaled by 0.5x

Normal Price: RTM prices at 1x

High Price: RTM prices scaled by 2x

Evaluation: Computes total reward for each strategy in each scenario.

Results Saving: Saves strategy rewards to strategy_results.csv for plotting.

Inputs:
synthetic_data.csv: From generate_synthetic_data.py.

degradation_model.pkl: From train_degradation_model.py.

Outputs:
strategy_results.csv: Contains columns Scenario, Strategy, and Reward for three scenarios and four strategies.

Console output: Model loading confirmation, episode rewards, and results saving confirmation.

Dependencies: pandas, numpy, gym, torch, joblib

## 4. plot_results.py
Purpose: Visualizes the synthetic data, RandomForest model performance, and strategy comparison to analyze the system’s behavior and outcomes.
Functionality:
Data and Model Loading:
Reads synthetic_data.csv and strategy_results.csv.

Loads degradation_model.pkl.

Converts timestamp_utc to datetime and computes delta_SOC.

Plots:
Synthetic Data:
Three subplots: SOC (%), Battery Current (A), and RTM Price ($/MWh) over time.

Displays temporal trends in battery operation and market prices.

RandomForest Model Performance:
Scatter plot of actual vs. predicted degradation on test data.

Includes a red diagonal line (perfect prediction) and MSE in the title.

Strategy Comparison:
Bar chart comparing total rewards for AI Agent, Always Charge, Always Discharge, and Simple RTM vs DAM across Low, Normal, and High Price scenarios.

Visualization Details:
Uses matplotlib for clear, labeled plots with legends and appropriate scales.

Ensures proper datetime formatting for time-series plots.

Inputs:
synthetic_data.csv: From generate_synthetic_data.py.

degradation_model.pkl: From train_degradation_model.py.

strategy_results.csv: From train_ai_agent.py.

Outputs:
Displays three plots (no file output).

Dependencies: pandas, numpy, matplotlib, sklearn, joblib

# System Workflow

## Data Generation:
generate_synthetic_data.py creates synthetic_data.csv with 7 days of battery and market data.

## Model Training:
train_degradation_model.py reads synthetic_data.csv, trains a RandomForestRegressor on degradation, and saves degradation_model.pkl.

## Optimization:
train_ai_agent.py reads synthetic_data.csv and degradation_model.pkl, trains a DQN agent, evaluates strategies, and saves results to strategy_results.csv.

## Visualization:
plot_results.py reads synthetic_data.csv, degradation_model.pkl, and strategy_results.csv to generate and display plots.

## Data Flow:
## synthetic_data.csv → train_degradation_model.py → degradation_model.pkl

## synthetic_data.csv + degradation_model.pkl → train_ai_agent.py → strategy_results.csv

## synthetic_data.csv + degradation_model.pkl + strategy_results.csv → plot_results.py → Plots

# Key Features

## Modularity: 
Each script handles a distinct task (data generation, modeling, optimization, visualization), making the system easy to maintain and extend.

## Realistic Simulation: 
Battery parameters and market prices are based on realistic assumptions, with degradation modeled as a function of operational variables.

## Advanced Optimization: 
Uses DQN for intelligent decision-making, compared against intuitive baselines (including the requested Simple RTM vs DAM strategy).

## Comprehensive Visualization: 
Provides insights into data trends, model accuracy, and strategy performance.

## Compatibility: 
Designed to work with the provided synthetic_data.csv format, ensuring all required columns are utilized.

# Dependencies
pandas: Data manipulation and CSV handling

numpy: Numerical computations

matplotlib: Plotting

sklearn: RandomForestRegressor and train-test split

gym: Reinforcement learning environment

torch: DQN neural network

joblib: Model serialization

Install via:
bash

pip install pandas numpy matplotlib sklearn gym torch

Running the Software
Environment Setup:
Ensure Python 3.6+ and dependencies are installed.

Place all four scripts in the same directory.

Execution Order:
bash

python generate_synthetic_data.py
python train_degradation_model.py
python train_ai_agent.py
python plot_results.py

# Outputs:
Files: synthetic_data.csv, degradation_model.pkl, strategy_results.csv

Console: MSE (model training), training rewards (AI agent), and confirmation messages

Plots: Synthetic data, RandomForest performance, strategy comparison

# Example Usage Scenario
A BESS operator wants to evaluate an AI-driven control strategy for a 360 Ah battery in a volatile electricity market. They:
Generate synthetic data to simulate 7 days of operation (generate_synthetic_data.py).

Train a RandomForest model to predict degradation based on SOC, delta_SOC, temperature, and current (train_degradation_model.py).

Use a DQN agent to learn optimal charging/discharging, comparing it against always charging, always discharging, and a simple price-based strategy (train_ai_agent.py).

Visualize the battery’s SOC trends, model accuracy, and strategy performance to decide which approach maximizes profit (plot_results.py).

Limitations and Potential Extensions
Training Episodes: The DQN agent trains for only 10 episodes for demonstration; increasing episodes (e.g., to 100) could improve performance but requires more computation.

Feature Set: The degradation model uses four features; additional features (e.g., Battery_Voltage, Cell_Temperature_1_Max) could be included for better accuracy.

Real Data: The system uses synthetic data; adapting it to real BESS data would require minor adjustments to data preprocessing.

Scalability: The system is designed for a single battery string; scaling to multiple strings or larger datasets may require optimization.
